---
title: "Network Analysis with R"
output:
  html_document:
    df_print: paged
---

## Exercises

These exercises will be easiest to complete if you keep the chapter 'Week 4, Class 2: Network Analysis with R' from the course book open at the same time. 

## Importing Network Data

Load the libraries required for these exercises: `tidyverse`, `igraph`, and `tidygraph`. Two of these have already been added to the code chunk. Add the third. 

```{r}
library(tidyverse)
library(igraph)
```


Next, load in the dataframe for your own network data. The code chunk below contains the code to do this for the sample data we used in the slides: add the path to the network data from the shared workspace. 

```{r}
df = read_csv("")
```

Summarise the data so that you it contains one instance of each edge, plus the weight, and save this as a new object called `edge_list`. 

The basic commands to do this are added below, but you need to input the correct columns to the `group_by()` function, plus tell the `tally()` function to name the count column 'weight'.  

```{r}
edge_list = df %>% 
  group_by() %>% # fill in the correct column names here
  tally() # add an argument 'name = ' 

```

In the code chunk below, turn the network object in to an undirected `tbl_graph`, named `g1`. 

```{r}

g1 = edge_list %>% as_tbl_graph(directed = F)

```

With your new graph object `g1`, calculate a number of global metric statistics and save them as R objects: *density*, called `d1`, *global clustering*, called `c1`, and *average path length*, called `p1`. The first is done for you. 

```{r}

d1 = g1 %>% igraph::graph.density()
c1 = 
p1 = 

```

In the chunk below, follow the same steps as above to load the letters data from the lecture and turn it into a network object, called `g2`

```{r}

df2 = read_csv('data/letter_data.csv')

# add further steps below here:


```

Generate the same set of statistics and call them `d2`, `c2`, `p2` (copy and paste is your friend here)

```{r}

```


Compare the two networks (if you have correctly created all the relevant statistics, running the code chunk below will result in a dataframe containing them, for easy comparison) 

Based on the information from the lecture, how would you describe these two networks, and their differences and similarities?

```{r}
stats_df = tibble(names = c('density', 'global clustering', 'average path length'), stats_g1 = c(d1,c1,p1), stats_g2 = c(d2,c2,p2))

```

Next, generate a table of your nodes with a number of network statistics. 

A template has been done for you, but you need to make a number of changes:

-   change the degree method from 'in' to 'all'.
-   change the betweenness centrality measurement to undirected
-   add your weights column to the eigenvector centrality measurement
-   Change the closeness centrality to only consider outgoing links.


```{r}
nodes_table = g1 %>%
  mutate(degree = centrality_degree(mode = 'in')) %>% 
  mutate(between = centrality_betweenness(directed = TRUE)) %>% 
  mutate(eigen = centrality_eigen(weights = NULL, directed = F)) %>% 
  mutate(closeness = centrality_closeness(mode = 'in')) %>% 
  as_tibble() # this command turns the nodes table of the network object into an ordinary dataframe.
```

We can use this table to graph the *degree distribution*, from yesterday's class. The code is done for you, but in order to make it readable, change the `binwidth` parameter to something appropriate for this network. 
The binwidth controls how many values are represented by a single bar in the chart. 

```{r}
nodes_table %>% ggplot() + geom_histogram(aes(x = degree), binwidth = 10)
```

Below this, do the same for the `between` metric (hint, you can copy and paste, and just change the x value):

```{r}

```

The code to create a log-log plot is given below: just run the chunk and it will display the correct graph. What does this tell you about the structure of your particular network?

```{r}
nodes_table %>% 
  count(degree) %>% 
  ggplot() + 
  geom_point(aes(degree, n)) + 
  labs(x = 'Number of nodes', y = 'Degree score') + scale_x_log10() + scale_y_log10()
```

Sort the table in descending order of degree score. Which nodes are at the top? Below the chunk, speculate why they might be the most 'central', and whether this is surprising. 

```{r}

```

Next, sort by `between`. Take a look at the top-ranked nodes. Are there any here which differ significantly from the top-ranked by degree score? What role might these nodes occupy?

Another way to look at this is by plotting the `degree` metric against the `between` metric for all the nodes in the graph. The code for this is below. 

```{r}

nodes_table %>% 
  ggplot() +
  geom_point(aes(x = degree, y = between))

```

Thinking back to your computational literacy course, what does this tell us about the relationship between degree and betweenness centrality? What implication does this have for the usefulness of the metrics?


## Joining attributes to the table



